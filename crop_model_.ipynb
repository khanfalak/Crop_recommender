{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing and metrics evaluation**"
      ],
      "metadata": {
        "id": "SiZRank5__pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q xgboost scikit-learn tensorflow==2.15.0   # uncomment if needed\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "DATA_PATH = \"/content/Crop_recommendation.csv\"  # change if needed\n",
        "\n",
        "\n",
        "# 1) Load dataset (robust target detection)\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Loaded CSV shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# try to find a target column name automatically\n",
        "for candidate in ['label','Label','crop','Crop','target','Target','y','Y','class','Class']:\n",
        "    if candidate in df.columns:\n",
        "        target_col = candidate\n",
        "        break\n",
        "else:\n",
        "    target_col = df.columns[-1]  # fallback: last column\n",
        "print(\"Using target column:\", target_col)\n",
        "\n",
        "# 2) Basic preprocessing: drop NA, separate X,y\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col].astype(str)   # ensure categorical/string for LabelEncoder\n",
        "\n",
        "# handle any non-numeric features: simple one-hot or label encode\n",
        "# If there are categorical/text columns, do one-hot for simplicity\n",
        "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
        "if len(cat_cols):\n",
        "    X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
        "print(\"Feature shape after encoding:\", X.shape)\n",
        "\n",
        "# 3) Encode labels\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Classes ({}): {}\".format(num_classes, le.classes_))\n",
        "\n",
        "# 4) Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y_enc, test_size=0.20, random_state=42, stratify=y_enc)\n",
        "print(\"Train/Test sizes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# 5) Scale features (important for SGD)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Utility: evaluation printing\n",
        "def print_metrics(name, y_true, y_pred, y_proba=None):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy: {:.4f}\".format(acc))\n",
        "    print(\"Precision (weighted): {:.4f}\".format(prec))\n",
        "    print(\"Recall (weighted): {:.4f}\".format(rec))\n",
        "    print(\"F1-score (weighted): {:.4f}\".format(f1))\n",
        "    print(\"Classification report:\\n\", classification_report(y_true, y_pred, target_names=le.classes_, zero_division=0))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "    if (y_proba is not None) and (num_classes == 2):\n",
        "        try:\n",
        "            auc = roc_auc_score(y_true, y_proba[:,1])\n",
        "            print(\"ROC AUC: {:.4f}\".format(auc))\n",
        "        except Exception:\n",
        "            pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twlJaICqnjdO",
        "outputId": "1550b2fb-b08b-4889-b140-a304b568be5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded CSV shape: (2200, 8)\n",
            "Columns: ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label']\n",
            "Using target column: label\n",
            "Feature shape after encoding: (2200, 7)\n",
            "Classes (22): ['apple' 'banana' 'blackgram' 'chickpea' 'coconut' 'coffee' 'cotton'\n",
            " 'grapes' 'jute' 'kidneybeans' 'lentil' 'maize' 'mango' 'mothbeans'\n",
            " 'mungbean' 'muskmelon' 'orange' 'papaya' 'pigeonpeas' 'pomegranate'\n",
            " 'rice' 'watermelon']\n",
            "Train/Test sizes: (1760, 7) (440, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL 1: SGDClassifier **"
      ],
      "metadata": {
        "id": "K8Q52mIJAO6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGDClassifier(loss='log_loss', penalty='elasticnet', max_iter=2000, tol=1e-3, random_state=42)\n",
        "sgd.fit(X_train_scaled, y_train)\n",
        "y_pred_sgd = sgd.predict(X_test_scaled)\n",
        "y_proba_sgd = None\n",
        "if hasattr(sgd, \"predict_proba\"):\n",
        "    y_proba_sgd = sgd.predict_proba(X_test_scaled)\n",
        "print_metrics(\"SGDClassifier (sklearn)\", y_test, y_pred_sgd, y_proba_sgd)\n",
        "\n",
        "# Save SGD model (sklearn)\n",
        "import joblib\n",
        "joblib.dump(sgd, \"sgd_model.joblib\")\n",
        "joblib.dump(scaler, \"scaler.joblib\")\n",
        "joblib.dump(le, \"label_encoder.joblib\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFs4LAH1ALiJ",
        "outputId": "e699baa2-aaea-47da-c9cd-883a9b3534cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== SGDClassifier (sklearn) ===\n",
            "Accuracy: 0.9705\n",
            "Precision (weighted): 0.9745\n",
            "Recall (weighted): 0.9705\n",
            "F1-score (weighted): 0.9712\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       apple       1.00      1.00      1.00        20\n",
            "      banana       1.00      1.00      1.00        20\n",
            "   blackgram       1.00      0.95      0.97        20\n",
            "    chickpea       1.00      1.00      1.00        20\n",
            "     coconut       1.00      1.00      1.00        20\n",
            "      coffee       1.00      1.00      1.00        20\n",
            "      cotton       1.00      1.00      1.00        20\n",
            "      grapes       1.00      1.00      1.00        20\n",
            "        jute       0.83      0.95      0.88        20\n",
            " kidneybeans       1.00      1.00      1.00        20\n",
            "      lentil       1.00      0.95      0.97        20\n",
            "       maize       0.77      1.00      0.87        20\n",
            "       mango       1.00      1.00      1.00        20\n",
            "   mothbeans       0.94      0.85      0.89        20\n",
            "    mungbean       1.00      1.00      1.00        20\n",
            "   muskmelon       1.00      1.00      1.00        20\n",
            "      orange       1.00      1.00      1.00        20\n",
            "      papaya       1.00      0.95      0.97        20\n",
            "  pigeonpeas       1.00      0.90      0.95        20\n",
            " pomegranate       1.00      0.90      0.95        20\n",
            "        rice       0.90      0.90      0.90        20\n",
            "  watermelon       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           0.97       440\n",
            "   macro avg       0.97      0.97      0.97       440\n",
            "weighted avg       0.97      0.97      0.97       440\n",
            "\n",
            "Confusion matrix:\n",
            " [[20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 19  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 19  0  0  1  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  3  0 17  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0 18  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0 18  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0 18  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I75-vE44gnnd",
        "outputId": "01f3035e-a30f-4f75-f17f-b77350a95404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [08:25:36] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== XGBoost ===\n",
            "Accuracy: 0.9932\n",
            "Precision (weighted): 0.9935\n",
            "Recall (weighted): 0.9932\n",
            "F1-score (weighted): 0.9931\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       apple       1.00      1.00      1.00        20\n",
            "      banana       1.00      1.00      1.00        20\n",
            "   blackgram       1.00      1.00      1.00        20\n",
            "    chickpea       1.00      1.00      1.00        20\n",
            "     coconut       1.00      1.00      1.00        20\n",
            "      coffee       1.00      1.00      1.00        20\n",
            "      cotton       1.00      1.00      1.00        20\n",
            "      grapes       1.00      1.00      1.00        20\n",
            "        jute       0.95      1.00      0.98        20\n",
            " kidneybeans       1.00      1.00      1.00        20\n",
            "      lentil       1.00      0.90      0.95        20\n",
            "       maize       1.00      1.00      1.00        20\n",
            "       mango       1.00      1.00      1.00        20\n",
            "   mothbeans       0.95      1.00      0.98        20\n",
            "    mungbean       0.95      1.00      0.98        20\n",
            "   muskmelon       1.00      1.00      1.00        20\n",
            "      orange       1.00      1.00      1.00        20\n",
            "      papaya       1.00      1.00      1.00        20\n",
            "  pigeonpeas       1.00      1.00      1.00        20\n",
            " pomegranate       1.00      1.00      1.00        20\n",
            "        rice       1.00      0.95      0.97        20\n",
            "  watermelon       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           0.99       440\n",
            "   macro avg       0.99      0.99      0.99       440\n",
            "weighted avg       0.99      0.99      0.99       440\n",
            "\n",
            "Confusion matrix:\n",
            " [[20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  1  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 19  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xgb_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# ========== MODEL 2: XGBoost ==========\n",
        "# Use scikit-learn API of XGBoost\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softprob' if num_classes>2 else 'binary:logistic',\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss' if num_classes>2 else 'logloss',\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "xgb_clf.fit(X_train, y_train)   # note: XGBoost can take unscaled features\n",
        "y_pred_xgb = xgb_clf.predict(X_test)\n",
        "y_proba_xgb = xgb_clf.predict_proba(X_test)\n",
        "print_metrics(\"XGBoost\", y_test, y_pred_xgb, y_proba_xgb)\n",
        "joblib.dump(xgb_clf, \"xgb_model.joblib\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== MODEL 3: Soft Voting Ensemble (SGD + XGBoost) ==========\n",
        "# VotingClassifier expects estimators that implement predict_proba for soft voting.\n",
        "# sklearn.SGDClassifier with loss='log' supports predict_proba. XGB supports predict_proba.\n",
        "voting = VotingClassifier(estimators=[('sgd', sgd), ('xgb', xgb_clf)], voting='soft', n_jobs=-1)\n",
        "voting.fit(X_train_scaled, y_train)   # both need scaled input; xgb was trained on raw earlier, but here we train voting on scaled\n",
        "y_pred_voting = voting.predict(X_test_scaled)\n",
        "# get predict_proba if available\n",
        "if hasattr(voting, \"predict_proba\"):\n",
        "    y_proba_voting = voting.predict_proba(X_test_scaled)\n",
        "else:\n",
        "    y_proba_voting = None\n",
        "print_metrics(\"Soft Voting Ensemble (SGD + XGB)\", y_test, y_pred_voting, y_proba_voting)\n",
        "joblib.dump(voting, \"voting_model.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDrOU8_Qnp-G",
        "outputId": "00ab429c-189e-4118-c04b-0ad82f8c8d64"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Soft Voting Ensemble (SGD + XGB) ===\n",
            "Accuracy: 0.9886\n",
            "Precision (weighted): 0.9890\n",
            "Recall (weighted): 0.9886\n",
            "F1-score (weighted): 0.9886\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       apple       1.00      1.00      1.00        20\n",
            "      banana       1.00      1.00      1.00        20\n",
            "   blackgram       1.00      1.00      1.00        20\n",
            "    chickpea       1.00      1.00      1.00        20\n",
            "     coconut       1.00      1.00      1.00        20\n",
            "      coffee       1.00      1.00      1.00        20\n",
            "      cotton       1.00      1.00      1.00        20\n",
            "      grapes       1.00      1.00      1.00        20\n",
            "        jute       0.95      0.95      0.95        20\n",
            " kidneybeans       1.00      1.00      1.00        20\n",
            "      lentil       1.00      0.90      0.95        20\n",
            "       maize       0.95      1.00      0.98        20\n",
            "       mango       1.00      1.00      1.00        20\n",
            "   mothbeans       0.95      1.00      0.98        20\n",
            "    mungbean       0.95      1.00      0.98        20\n",
            "   muskmelon       1.00      1.00      1.00        20\n",
            "      orange       1.00      1.00      1.00        20\n",
            "      papaya       1.00      1.00      1.00        20\n",
            "  pigeonpeas       1.00      0.95      0.97        20\n",
            " pomegranate       1.00      1.00      1.00        20\n",
            "        rice       0.95      0.95      0.95        20\n",
            "  watermelon       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           0.99       440\n",
            "   macro avg       0.99      0.99      0.99       440\n",
            "weighted avg       0.99      0.99      0.99       440\n",
            "\n",
            "Confusion matrix:\n",
            " [[20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 18  0  0  1  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 19  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 19  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['voting_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== MODEL 4: Keras Neural Network (for TFLite conversion) ==========\n",
        "# We'll build a small MLP. Input dims from X (scaled used).\n",
        "input_dim = X_train_scaled.shape[1]\n",
        "\n",
        "def make_keras_model(input_dim, num_classes):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Input(shape=(input_dim,)))\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    if num_classes == 2:\n",
        "        model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    else:\n",
        "        model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
        "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "keras_model = make_keras_model(input_dim, num_classes)\n",
        "# Use scaled features for NN\n",
        "history = keras_model.fit(X_train_scaled, y_train, validation_split=0.1, epochs=40, batch_size=32, verbose=1)\n",
        "# Evaluate\n",
        "if num_classes == 2:\n",
        "    y_proba_keras = keras_model.predict(X_test_scaled).reshape(-1)\n",
        "    y_pred_keras = (y_proba_keras > 0.5).astype(int)\n",
        "    y_proba_keras = np.vstack([1-y_proba_keras, y_proba_keras]).T\n",
        "else:\n",
        "    y_proba_keras = keras_model.predict(X_test_scaled)\n",
        "    y_pred_keras = np.argmax(y_proba_keras, axis=1)\n",
        "print_metrics(\"Keras NN\", y_test, y_pred_keras, y_proba_keras)\n",
        "\n",
        "# Save raw Keras model (SavedModel)\n",
        "keras_model.export(\"keras_crop_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V_EtSLQnp7w",
        "outputId": "63aa8d6b-50f4-44b6-e05d-f64d8ee24d26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1995 - loss: 2.8880 - val_accuracy: 0.5398 - val_loss: 1.9809\n",
            "Epoch 2/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5725 - loss: 1.8071 - val_accuracy: 0.8466 - val_loss: 0.9679\n",
            "Epoch 3/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8133 - loss: 0.9333 - val_accuracy: 0.8750 - val_loss: 0.5425\n",
            "Epoch 4/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8456 - loss: 0.5803 - val_accuracy: 0.9489 - val_loss: 0.3860\n",
            "Epoch 5/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8965 - loss: 0.4142 - val_accuracy: 0.9091 - val_loss: 0.3054\n",
            "Epoch 6/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9018 - loss: 0.3261 - val_accuracy: 0.9318 - val_loss: 0.2587\n",
            "Epoch 7/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2883 - val_accuracy: 0.9375 - val_loss: 0.2135\n",
            "Epoch 8/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.2623 - val_accuracy: 0.9659 - val_loss: 0.1828\n",
            "Epoch 9/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.2011 - val_accuracy: 0.9489 - val_loss: 0.1689\n",
            "Epoch 10/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9384 - loss: 0.1982 - val_accuracy: 0.9489 - val_loss: 0.1506\n",
            "Epoch 11/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1673 - val_accuracy: 0.9773 - val_loss: 0.1291\n",
            "Epoch 12/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1607 - val_accuracy: 0.9659 - val_loss: 0.1177\n",
            "Epoch 13/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.1315 - val_accuracy: 0.9659 - val_loss: 0.1146\n",
            "Epoch 14/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1310 - val_accuracy: 0.9716 - val_loss: 0.1065\n",
            "Epoch 15/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.1281 - val_accuracy: 0.9659 - val_loss: 0.0949\n",
            "Epoch 16/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.1170 - val_accuracy: 0.9773 - val_loss: 0.0848\n",
            "Epoch 17/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.1207 - val_accuracy: 0.9886 - val_loss: 0.0812\n",
            "Epoch 18/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.1089 - val_accuracy: 0.9773 - val_loss: 0.0847\n",
            "Epoch 19/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1033 - val_accuracy: 0.9545 - val_loss: 0.0842\n",
            "Epoch 20/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0836 - val_accuracy: 0.9886 - val_loss: 0.0757\n",
            "Epoch 21/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.1094 - val_accuracy: 0.9830 - val_loss: 0.0722\n",
            "Epoch 22/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9649 - loss: 0.0906 - val_accuracy: 0.9602 - val_loss: 0.0946\n",
            "Epoch 23/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9532 - loss: 0.1168 - val_accuracy: 0.9659 - val_loss: 0.0755\n",
            "Epoch 24/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.0946 - val_accuracy: 0.9773 - val_loss: 0.0763\n",
            "Epoch 25/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.0813 - val_accuracy: 0.9830 - val_loss: 0.0635\n",
            "Epoch 26/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.0772 - val_accuracy: 0.9716 - val_loss: 0.0652\n",
            "Epoch 27/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 0.0720 - val_accuracy: 0.9830 - val_loss: 0.0671\n",
            "Epoch 28/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0858 - val_accuracy: 0.9602 - val_loss: 0.0686\n",
            "Epoch 29/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.0768 - val_accuracy: 0.9943 - val_loss: 0.0560\n",
            "Epoch 30/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0526 - val_accuracy: 0.9830 - val_loss: 0.0600\n",
            "Epoch 31/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0654 - val_accuracy: 0.9773 - val_loss: 0.0715\n",
            "Epoch 32/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0550 - val_accuracy: 0.9773 - val_loss: 0.0574\n",
            "Epoch 33/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0671 - val_accuracy: 0.9830 - val_loss: 0.0542\n",
            "Epoch 34/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.0634 - val_accuracy: 0.9830 - val_loss: 0.0507\n",
            "Epoch 35/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0595 - val_accuracy: 0.9943 - val_loss: 0.0522\n",
            "Epoch 36/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0554 - val_accuracy: 0.9943 - val_loss: 0.0449\n",
            "Epoch 37/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.0589 - val_accuracy: 0.9886 - val_loss: 0.0479\n",
            "Epoch 38/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.0536 - val_accuracy: 0.9773 - val_loss: 0.0567\n",
            "Epoch 39/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.0583 - val_accuracy: 0.9716 - val_loss: 0.0578\n",
            "Epoch 40/40\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0620 - val_accuracy: 0.9716 - val_loss: 0.0521\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\n",
            "=== Keras NN ===\n",
            "Accuracy: 0.9886\n",
            "Precision (weighted): 0.9887\n",
            "Recall (weighted): 0.9886\n",
            "F1-score (weighted): 0.9886\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       apple       1.00      1.00      1.00        20\n",
            "      banana       1.00      1.00      1.00        20\n",
            "   blackgram       1.00      1.00      1.00        20\n",
            "    chickpea       1.00      1.00      1.00        20\n",
            "     coconut       1.00      1.00      1.00        20\n",
            "      coffee       1.00      1.00      1.00        20\n",
            "      cotton       1.00      1.00      1.00        20\n",
            "      grapes       1.00      1.00      1.00        20\n",
            "        jute       0.89      0.85      0.87        20\n",
            " kidneybeans       1.00      1.00      1.00        20\n",
            "      lentil       1.00      1.00      1.00        20\n",
            "       maize       1.00      1.00      1.00        20\n",
            "       mango       1.00      1.00      1.00        20\n",
            "   mothbeans       1.00      1.00      1.00        20\n",
            "    mungbean       1.00      1.00      1.00        20\n",
            "   muskmelon       1.00      1.00      1.00        20\n",
            "      orange       1.00      1.00      1.00        20\n",
            "      papaya       1.00      1.00      1.00        20\n",
            "  pigeonpeas       1.00      1.00      1.00        20\n",
            " pomegranate       1.00      1.00      1.00        20\n",
            "        rice       0.86      0.90      0.88        20\n",
            "  watermelon       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           0.99       440\n",
            "   macro avg       0.99      0.99      0.99       440\n",
            "weighted avg       0.99      0.99      0.99       440\n",
            "\n",
            "Confusion matrix:\n",
            " [[20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  3  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0 18  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20]]\n",
            "Saved artifact at 'keras_crop_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 7), dtype=tf.float32, name='keras_tensor_22')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 22), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136158834045200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158787731088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158787730896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158787731280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158787730512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158787727440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Convert Keras -> TFLite ==========\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "# Optional: quantization (uncomment if desired)\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Provide a representative_dataset_gen if doing post-training quantization (not added here)\n",
        "tflite_model = converter.convert()\n",
        "open(\"keras_crop_model.tflite\", \"wb\").write(tflite_model)\n",
        "print(\"Saved TFLite model to keras_crop_model.tflite\")\n",
        "# You can test the tflite model using the TFLite interpreter:\n",
        "interpreter = tf.lite.Interpreter(model_path=\"keras_crop_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"TFLite input details:\", input_details)\n",
        "print(\"TFLite output details:\", output_details)\n",
        "\n",
        "# Example wrapper for TFLite inference\n",
        "def run_tflite_inference(tflite_path, sample_array):\n",
        "    inter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    inter.allocate_tensors()\n",
        "    inp = inter.get_input_details()[0]\n",
        "    out = inter.get_output_details()[0]\n",
        "    # ensure sample_array shape matches\n",
        "    sample = np.array(sample_array, dtype=np.float32).reshape(1, -1)\n",
        "    inter.set_tensor(inp['index'], sample)\n",
        "    inter.invoke()\n",
        "    pred = inter.get_tensor(out['index'])\n",
        "    return pred\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJAYWs9gnpyo",
        "outputId": "4139637f-2cbf-4043-92d1-080c11b5d2fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmp0k72j476'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 7), dtype=tf.float32, name='keras_tensor_22')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 22), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136158834045200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158787731088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158787730896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158787731280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158787730512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158787727440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved TFLite model to keras_crop_model.tflite\n",
            "TFLite input details: [{'name': 'serving_default_keras_tensor_22:0', 'index': 0, 'shape': array([1, 7], dtype=int32), 'shape_signature': array([-1,  7], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "TFLite output details: [{'name': 'StatefulPartitionedCall_1:0', 'index': 10, 'shape': array([ 1, 22], dtype=int32), 'shape_signature': array([-1, 22], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Optional: Distill Ensemble -> Keras Student (so you can TFLite the student) ==========\n",
        "# We'll predict soft probabilities with the voting ensemble and train a small Keras model to mimic them.\n",
        "if hasattr(voting, \"predict_proba\"):\n",
        "    soft_targets = voting.predict_proba(X_train_scaled)\n",
        "    # build student model same architecture but smaller\n",
        "    student = make_keras_model(input_dim, num_classes)\n",
        "    # If multi-class, use categorical crossentropy on the soft labels -> train with probabilities (use from_logits=False)\n",
        "    if num_classes == 2:\n",
        "        # binary distillation: use probability of class 1\n",
        "        student.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        teacher_labels = soft_targets[:,1]\n",
        "    else:\n",
        "        student.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        teacher_labels = soft_targets  # soft targets\n",
        "    # For categorical_crossentropy with soft labels, use y as one-hot soft vectors\n",
        "    if num_classes > 2:\n",
        "        student.fit(X_train_scaled, teacher_labels, epochs=50, batch_size=64, verbose=1, validation_split=0.1)\n",
        "        y_proba_student = student.predict(X_test_scaled)\n",
        "        y_pred_student = np.argmax(y_proba_student, axis=1)\n",
        "    else:\n",
        "        student.fit(X_train_scaled, teacher_labels, epochs=50, batch_size=64, verbose=1, validation_split=0.1)\n",
        "        y_proba_student = student.predict(X_test_scaled).reshape(-1)\n",
        "        y_pred_student = (y_proba_student > 0.5).astype(int)\n",
        "    print_metrics(\"Student (distilled from Ensemble)\", y_test, y_pred_student, y_proba_student)\n",
        "    # Save and convert student to TFLite\n",
        "    student.export(\"student_model_savedmodel\")\n",
        "    converter_s = tf.lite.TFLiteConverter.from_saved_model(\"student_model_savedmodel\")\n",
        "    tflite_student = converter_s.convert()\n",
        "    open(\"student_model.tflite\", \"wb\").write(tflite_student)\n",
        "    print(\"Saved distilled student TFLite:\", \"student_model.tflite\")\n",
        "\n",
        "print(\"\\nAll done. Files saved in the Colab working directory:\")\n",
        "print(os.listdir('.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBiL8xZWnpvj",
        "outputId": "21832cc0-1e8f-4018-8480-3f22d9e0cb17"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.1451 - loss: 3.0057 - val_accuracy: 0.5057 - val_loss: 2.5574\n",
            "Epoch 2/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5219 - loss: 2.4184 - val_accuracy: 0.6420 - val_loss: 1.8761\n",
            "Epoch 3/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6645 - loss: 1.7727 - val_accuracy: 0.7727 - val_loss: 1.2819\n",
            "Epoch 4/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8000 - loss: 1.2493 - val_accuracy: 0.8977 - val_loss: 0.9322\n",
            "Epoch 5/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8488 - loss: 0.9474 - val_accuracy: 0.9205 - val_loss: 0.7675\n",
            "Epoch 6/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 0.8134 - val_accuracy: 0.9375 - val_loss: 0.6753\n",
            "Epoch 7/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8895 - loss: 0.6995 - val_accuracy: 0.9489 - val_loss: 0.6181\n",
            "Epoch 8/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9038 - loss: 0.6447 - val_accuracy: 0.9432 - val_loss: 0.5749\n",
            "Epoch 9/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.6042 - val_accuracy: 0.9432 - val_loss: 0.5453\n",
            "Epoch 10/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9144 - loss: 0.5874 - val_accuracy: 0.9432 - val_loss: 0.5211\n",
            "Epoch 11/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.5688 - val_accuracy: 0.9489 - val_loss: 0.5011\n",
            "Epoch 12/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.5435 - val_accuracy: 0.9602 - val_loss: 0.4927\n",
            "Epoch 13/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9398 - loss: 0.5288 - val_accuracy: 0.9659 - val_loss: 0.4823\n",
            "Epoch 14/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9449 - loss: 0.5149 - val_accuracy: 0.9545 - val_loss: 0.4719\n",
            "Epoch 15/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9456 - loss: 0.5018 - val_accuracy: 0.9602 - val_loss: 0.4686\n",
            "Epoch 16/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9492 - loss: 0.5141 - val_accuracy: 0.9659 - val_loss: 0.4622\n",
            "Epoch 17/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.5117 - val_accuracy: 0.9602 - val_loss: 0.4581\n",
            "Epoch 18/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9546 - loss: 0.4969 - val_accuracy: 0.9659 - val_loss: 0.4587\n",
            "Epoch 19/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9599 - loss: 0.4942 - val_accuracy: 0.9716 - val_loss: 0.4557\n",
            "Epoch 20/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9582 - loss: 0.4907 - val_accuracy: 0.9659 - val_loss: 0.4517\n",
            "Epoch 21/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.4950 - val_accuracy: 0.9659 - val_loss: 0.4460\n",
            "Epoch 22/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9579 - loss: 0.4840 - val_accuracy: 0.9716 - val_loss: 0.4519\n",
            "Epoch 23/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9591 - loss: 0.4952 - val_accuracy: 0.9545 - val_loss: 0.4425\n",
            "Epoch 24/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9606 - loss: 0.4824 - val_accuracy: 0.9659 - val_loss: 0.4473\n",
            "Epoch 25/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9590 - loss: 0.4832 - val_accuracy: 0.9602 - val_loss: 0.4390\n",
            "Epoch 26/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.4705 - val_accuracy: 0.9716 - val_loss: 0.4403\n",
            "Epoch 27/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9581 - loss: 0.4857 - val_accuracy: 0.9659 - val_loss: 0.4423\n",
            "Epoch 28/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9651 - loss: 0.4682 - val_accuracy: 0.9659 - val_loss: 0.4366\n",
            "Epoch 29/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9568 - loss: 0.4690 - val_accuracy: 0.9659 - val_loss: 0.4426\n",
            "Epoch 30/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9618 - loss: 0.4585 - val_accuracy: 0.9659 - val_loss: 0.4447\n",
            "Epoch 31/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9625 - loss: 0.4670 - val_accuracy: 0.9659 - val_loss: 0.4430\n",
            "Epoch 32/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9644 - loss: 0.4765 - val_accuracy: 0.9659 - val_loss: 0.4357\n",
            "Epoch 33/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9668 - loss: 0.4657 - val_accuracy: 0.9659 - val_loss: 0.4338\n",
            "Epoch 34/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9525 - loss: 0.4786 - val_accuracy: 0.9545 - val_loss: 0.4362\n",
            "Epoch 35/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9652 - loss: 0.4594 - val_accuracy: 0.9659 - val_loss: 0.4382\n",
            "Epoch 36/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9644 - loss: 0.4755 - val_accuracy: 0.9545 - val_loss: 0.4345\n",
            "Epoch 37/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9607 - loss: 0.4764 - val_accuracy: 0.9716 - val_loss: 0.4351\n",
            "Epoch 38/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9659 - loss: 0.4686 - val_accuracy: 0.9716 - val_loss: 0.4326\n",
            "Epoch 39/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9714 - loss: 0.4705 - val_accuracy: 0.9545 - val_loss: 0.4352\n",
            "Epoch 40/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9659 - loss: 0.4729 - val_accuracy: 0.9716 - val_loss: 0.4356\n",
            "Epoch 41/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9723 - loss: 0.4704 - val_accuracy: 0.9602 - val_loss: 0.4316\n",
            "Epoch 42/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9680 - loss: 0.4612 - val_accuracy: 0.9773 - val_loss: 0.4351\n",
            "Epoch 43/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9693 - loss: 0.4493 - val_accuracy: 0.9602 - val_loss: 0.4326\n",
            "Epoch 44/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9660 - loss: 0.4573 - val_accuracy: 0.9602 - val_loss: 0.4292\n",
            "Epoch 45/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9642 - loss: 0.4608 - val_accuracy: 0.9602 - val_loss: 0.4271\n",
            "Epoch 46/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9712 - loss: 0.4552 - val_accuracy: 0.9659 - val_loss: 0.4280\n",
            "Epoch 47/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9654 - loss: 0.4575 - val_accuracy: 0.9659 - val_loss: 0.4313\n",
            "Epoch 48/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9622 - loss: 0.4527 - val_accuracy: 0.9716 - val_loss: 0.4363\n",
            "Epoch 49/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9732 - loss: 0.4587 - val_accuracy: 0.9773 - val_loss: 0.4354\n",
            "Epoch 50/50\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.4538 - val_accuracy: 0.9545 - val_loss: 0.4291\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\n",
            "=== Student (distilled from Ensemble) ===\n",
            "Accuracy: 0.9795\n",
            "Precision (weighted): 0.9805\n",
            "Recall (weighted): 0.9795\n",
            "F1-score (weighted): 0.9795\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       apple       1.00      1.00      1.00        20\n",
            "      banana       1.00      1.00      1.00        20\n",
            "   blackgram       0.95      0.95      0.95        20\n",
            "    chickpea       1.00      1.00      1.00        20\n",
            "     coconut       1.00      1.00      1.00        20\n",
            "      coffee       1.00      1.00      1.00        20\n",
            "      cotton       0.95      1.00      0.98        20\n",
            "      grapes       1.00      1.00      1.00        20\n",
            "        jute       0.83      0.95      0.88        20\n",
            " kidneybeans       1.00      1.00      1.00        20\n",
            "      lentil       0.95      1.00      0.98        20\n",
            "       maize       0.95      0.95      0.95        20\n",
            "       mango       1.00      1.00      1.00        20\n",
            "   mothbeans       1.00      0.95      0.97        20\n",
            "    mungbean       1.00      1.00      1.00        20\n",
            "   muskmelon       1.00      1.00      1.00        20\n",
            "      orange       1.00      1.00      1.00        20\n",
            "      papaya       1.00      1.00      1.00        20\n",
            "  pigeonpeas       1.00      0.95      0.97        20\n",
            " pomegranate       1.00      1.00      1.00        20\n",
            "        rice       0.94      0.80      0.86        20\n",
            "  watermelon       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           0.98       440\n",
            "   macro avg       0.98      0.98      0.98       440\n",
            "weighted avg       0.98      0.98      0.98       440\n",
            "\n",
            "Confusion matrix:\n",
            " [[20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 19  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0 19  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0 16  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20]]\n",
            "Saved artifact at 'student_model_savedmodel'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 7), dtype=tf.float32, name='keras_tensor_33')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 22), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136158405675728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158405677648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158405682448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158405685520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158405674576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136158405675536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved distilled student TFLite: student_model.tflite\n",
            "\n",
            "All done. Files saved in the Colab working directory:\n",
            "['.config', 'student_model_savedmodel', 'label_encoder.joblib', 'Crop_recommendation.csv', 'sgd_model.joblib', 'keras_crop_model.tflite', 'scaler.joblib', 'xgb_model.joblib', 'voting_model.joblib', 'student_model.tflite', 'keras_crop_model', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install geocoder requests\n",
        "\n",
        "import geocoder\n",
        "import requests\n",
        "import numpy as np\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "\n",
        "# ====== Step 1: Detect Location (lat, lon) ======\n",
        "lat , lon=19.994544, 74.379912\n",
        "#g = geocoder.ip('me')\n",
        "#if g.ok:\n",
        " #   lat, lon = g.latlng\n",
        "  #  print(f\"Detected location: lat={lat}, lon={lon}\")\n",
        "#else:\n",
        " #   lat, lon = 23.5, 85.3  # fallback: Ranchi, Jharkhand\n",
        "  #  print(\"Fallback location:\", lat, lon)\n",
        "\n",
        "# ====== Step 2: Fetch Weather Data (OpenWeatherMap API) ======\n",
        "OWM_API_KEY = \"dba1658fffa3efcf30741487f4e00a4c\"  # <-- replace with your key\n",
        "\n",
        "def get_weather(lat, lon, api_key):\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}&units=metric\"\n",
        "    r = requests.get(url).json()\n",
        "    temp = r['main']['temp']\n",
        "    humidity = r['main']['humidity']\n",
        "    rainfall = r.get('rain', {}).get('1h', 0.0)  # default 0 if missing\n",
        "    return temp, humidity, rainfall\n",
        "\n",
        "temperature, humidity, rainfall = get_weather(lat, lon, OWM_API_KEY)\n",
        "print(f\"Weather: Temp={temperature}°C, Humidity={humidity}%, Rainfall={rainfall} mm\")\n",
        "\n",
        "# ====== Step 3: Fetch Soil Data (SoilGrids API) ======\n",
        "def get_soil(lat, lon):\n",
        "    url = f\"https://rest.isric.org/soilgrids/v2.0/properties/query?lon={lon}&lat={lat}&property=nitrogen&property=phh2o&depth=0-5cm\"\n",
        "    r = requests.get(url).json()\n",
        "\n",
        "    # Debug: check keys available\n",
        "    # print(r.keys())\n",
        "\n",
        "    def safe_extract(layer_idx, depth_idx=0):\n",
        "        try:\n",
        "            val = r['properties']['layers'][layer_idx]['depths'][depth_idx]['values']['mean']\n",
        "            return float(val) if val is not None else None\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "    N = safe_extract(0)  # nitrogen\n",
        "    ph = safe_extract(1)  # phh2o\n",
        "\n",
        "    # Convert / fill defaults\n",
        "    N = N * 1000 if N is not None else 90.0   # default ~90 (mg/kg)\n",
        "    ph = ph if ph is not None else 6.5\n",
        "\n",
        "    # SoilGrids doesn’t give P, K → approximate or keep static defaults\n",
        "    P, K = 40.0, 40.0\n",
        "\n",
        "    return N, P, K, ph\n",
        "\n",
        "\n",
        "# ====== Step 4: Build Feature Vector ======\n",
        "N, P, K, ph = get_soil(lat, lon)\n",
        "print(f\"Soil Data -> N={N}, P={P}, K={K}, pH={ph}\")\n",
        "\n",
        "env_features = {\n",
        "    \"N\": N,\n",
        "    \"P\": P,\n",
        "    \"K\": K,\n",
        "    \"temperature\": temperature,\n",
        "    \"humidity\": humidity,\n",
        "    \"ph\": ph,\n",
        "    \"rainfall\": rainfall\n",
        "}\n",
        "print(\"Final feature vector:\", env_features)\n",
        "\n",
        "feature_vector = [\n",
        "    env_features[\"N\"],\n",
        "    env_features[\"P\"],\n",
        "    env_features[\"K\"],\n",
        "    env_features[\"temperature\"],\n",
        "    env_features[\"humidity\"],\n",
        "    env_features[\"ph\"],\n",
        "    env_features[\"rainfall\"]\n",
        "]\n",
        "feature_vector = np.array(feature_vector, dtype=np.float32).reshape(1, -1)\n",
        "\n",
        "# ====== Step 5: Load Preprocessing Objects ======\n",
        "scaler = joblib.load(\"scaler.joblib\")\n",
        "le = joblib.load(\"label_encoder.joblib\")\n",
        "X_scaled = scaler.transform(feature_vector)\n",
        "\n",
        "# ====== Step 6: Run Inference with TFLite Model ======\n",
        "interpreter = tf.lite.Interpreter(model_path=\"student_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], X_scaled.astype(np.float32))\n",
        "interpreter.invoke()\n",
        "prediction = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "# ====== Step 7: Decode Prediction ======\n",
        "if prediction.shape[1] == 1:  # binary case\n",
        "    pred_class = int(prediction[0][0] > 0.5)\n",
        "else:\n",
        "    pred_class = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "recommended_crop = le.inverse_transform([pred_class])[0]\n",
        "print(\"\\n🌾 Recommended Crop:\", recommended_crop)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgiqm44npao4",
        "outputId": "dba2f8de-c687-47ab-f977-87d94891ff6a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weather: Temp=28.27°C, Humidity=68%, Rainfall=0.0 mm\n",
            "Soil Data -> N=143000.0, P=40.0, K=40.0, pH=72.0\n",
            "Final feature vector: {'N': 143000.0, 'P': 40.0, 'K': 40.0, 'temperature': 28.27, 'humidity': 68, 'ph': 72.0, 'rainfall': 0.0}\n",
            "\n",
            "🌾 Recommended Crop: cotton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Crop_recommendation.csv\")\n",
        "\n",
        "# List of all unique crops in the dataset\n",
        "all_crops = df[\"label\"].unique()\n",
        "\n",
        "# Define rule-based crop rotation\n",
        "rotation_rules = {\n",
        "    # Cereals\n",
        "    \"rice\": [\"wheat\", \"mustard\", \"chickpea\", \"lentil\"],\n",
        "    \"wheat\": [\"rice\", \"maize\", \"pulses\", \"groundnut\"],\n",
        "    \"maize\": [\"soybean\", \"wheat\", \"potato\", \"pea\"],\n",
        "    \"barley\": [\"rice\", \"maize\", \"pulses\"],\n",
        "\n",
        "    # Pulses\n",
        "    \"lentil\": [\"rice\", \"maize\", \"sorghum\", \"mustard\"],\n",
        "    \"chickpea\": [\"rice\", \"maize\", \"sorghum\"],\n",
        "    \"pigeonpeas\": [\"rice\", \"wheat\", \"mustard\"],\n",
        "    \"mothbeans\": [\"sorghum\", \"pearl millet\", \"cowpea\"],\n",
        "    \"mungbean\": [\"rice\", \"wheat\", \"mustard\"],\n",
        "    \"blackgram\": [\"rice\", \"maize\", \"mustard\"],\n",
        "    \"kidneybeans\": [\"rice\", \"maize\", \"vegetables\"],\n",
        "\n",
        "    # Oilseeds\n",
        "    \"groundnut\": [\"wheat\", \"mustard\", \"vegetables\"],\n",
        "    \"soybean\": [\"wheat\", \"mustard\", \"vegetables\"],\n",
        "    \"mustard\": [\"rice\", \"maize\", \"vegetables\"],\n",
        "\n",
        "    # Fibre\n",
        "    \"cotton\": [\"wheat\", \"mustard\", \"pulses\", \"vegetables\"],\n",
        "    \"jute\": [\"wheat\", \"mustard\", \"pulses\"],\n",
        "\n",
        "    # Cash crops\n",
        "    \"sugarcane\": [\"wheat\", \"pulses\", \"vegetables\"],\n",
        "    \"coffee\": [\"banana\", \"black pepper\", \"ginger\"],\n",
        "\n",
        "    # Fruits\n",
        "    \"banana\": [\"vegetables\", \"pulses\", \"ginger\"],\n",
        "    \"mango\": [\"vegetables\", \"pulses\", \"groundnut\"],\n",
        "    \"grapes\": [\"wheat\", \"mustard\", \"pulses\"],\n",
        "    \"watermelon\": [\"maize\", \"pulses\", \"groundnut\"],\n",
        "    \"muskmelon\": [\"maize\", \"pulses\", \"groundnut\"],\n",
        "    \"apple\": [\"barley\", \"peas\", \"vegetables\"],\n",
        "    \"orange\": [\"vegetables\", \"pulses\", \"ginger\"],\n",
        "    \"papaya\": [\"vegetables\", \"legumes\", \"ginger\"],\n",
        "    \"pomegranate\": [\"wheat\", \"vegetables\", \"pulses\"],\n",
        "    \"coconut\": [\"banana\", \"vegetables\", \"ginger\"]\n",
        "}\n",
        "\n",
        "# Fallback recommender\n",
        "def recommend_next_crop(prev_crop):\n",
        "    if prev_crop in rotation_rules:\n",
        "        return rotation_rules[prev_crop]\n",
        "    else:\n",
        "        return [c for c in all_crops if c != prev_crop][:3]\n",
        "\n",
        "# Generate recommendations for all crops in dataset\n",
        "#for crop in all_crops:\n",
        "    #print(f\"After {crop} → {recommend_next_crop(crop)}\")\n",
        "print(f\"After {recommended_crop} -> {recommend_next_crop(recommended_crop)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXY2MHkrt9is",
        "outputId": "34e6dd63-86e9-48b1-8135-b8a74d8f25fd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After cotton -> ['wheat', 'mustard', 'pulses', 'vegetables']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CV-XUZEk-tcB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}